{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7-vHC5o6QvvE",
   "metadata": {
    "id": "7-vHC5o6QvvE"
   },
   "source": [
    "# ***Milestone 1 - Data Sanity ( by using Numpy and Pandas)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25c41f",
   "metadata": {
    "id": "7d25c41f"
   },
   "source": [
    "Impoorting Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926a0c4",
   "metadata": {
    "id": "0926a0c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,ExtraTreesRegressor\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e0cac",
   "metadata": {},
   "source": [
    "Function for data modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in_days(melt, lags, ffday, customer_id_col, create_date_col, net_amount_col):\n",
    "    for i in range(ffday, lags+1):\n",
    "        melt['Last-'+str(i)+'day_Sales'] = melt.groupby([customer_id_col])[net_amount_col].shift(i)\n",
    "    \n",
    "    melt = melt.reset_index(drop = True)\n",
    "    \n",
    "    for i in range(ffday, lags+1):\n",
    "        melt['Last-'+str(i)+'day_Diff']  = melt.groupby([customer_id_col])['Last-'+str(i)+'day_Sales'].diff()\n",
    "    melt = melt.fillna(0)\n",
    "    return melt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36df00",
   "metadata": {
    "id": "0d36df00"
   },
   "source": [
    "1. Use the PRS dataset to create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fcd15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "498fcd15",
    "outputId": "948def4a-c99f-4d0a-e151-257ddee7ffea"
   },
   "outputs": [],
   "source": [
    "harsh=pd.read_csv(\"Final.csv\")\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645c7b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0645c7b2",
    "outputId": "b1ff43d1-b558-4b55-9c9e-379f717618df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ad645",
   "metadata": {
    "id": "f91ad645"
   },
   "source": [
    "2. Check the description of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a89c06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "02a89c06",
    "outputId": "dc41a543-5f92-4f5f-cab7-6016714e6e6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "harsh.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc416a38",
   "metadata": {
    "id": "fc416a38"
   },
   "source": [
    "3. Check the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa7621",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2aa7621",
    "outputId": "3b18f7cf-a808-466c-d344-40fdd93d960a"
   },
   "outputs": [],
   "source": [
    "harsh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d042f9d",
   "metadata": {
    "id": "2d042f9d"
   },
   "source": [
    "4. Check the data frame informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c9bad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c1c9bad",
    "outputId": "49910341-cb05-4ac8-be3b-666872194ab6"
   },
   "outputs": [],
   "source": [
    "harsh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d290331",
   "metadata": {
    "id": "1d290331"
   },
   "source": [
    "5. Check for the Null values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e77fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17e77fb8",
    "outputId": "ded4453f-dc2e-4904-8929-e78c48092e69"
   },
   "outputs": [],
   "source": [
    "harsh.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4bca9",
   "metadata": {
    "id": "9fc4bca9"
   },
   "source": [
    "6. Replace all the null values with \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd250c20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd250c20",
    "outputId": "2011d26c-01b4-4345-b178-ed4672d33f78"
   },
   "outputs": [],
   "source": [
    "harsh=harsh.fillna(\"NaN\")\n",
    "harsh.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44f4d6",
   "metadata": {
    "id": "3b44f4d6"
   },
   "source": [
    "7. Change the format of date columns - \"ORDER_CREATION_DATE\" to datetime[64] with the format as \"%Y%m%d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db106e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "9db106e6",
    "outputId": "59296575-b027-4ff4-f347-32bcaada49a3"
   },
   "outputs": [],
   "source": [
    "harsh['ORDER_CREATION_DATE'] = pd.to_datetime(harsh['ORDER_CREATION_DATE'], format='%Y%m%d')\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a71e1",
   "metadata": {
    "id": "0f5a71e1"
   },
   "source": [
    "8. Do the same activity for the other date field i.e. \"REQUESTED_DELIVERY_DATE\" to datetime[64] with the format as \"%Y%m%d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da11c71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "4da11c71",
    "outputId": "09c71c76-64ab-460d-b109-ff28ee719e47"
   },
   "outputs": [],
   "source": [
    "harsh['REQUESTED_DELIVERY_DATE'] = pd.to_datetime(harsh['REQUESTED_DELIVERY_DATE'], format='%Y%m%d')\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cb243",
   "metadata": {
    "id": "422cb243"
   },
   "source": [
    "9. Sanity check - Check how many records are having order date greater than the delivery date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1370e92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1370e92",
    "outputId": "d7cc2f40-7777-46f2-fb2a-9f2cdfcda966"
   },
   "outputs": [],
   "source": [
    "a=(harsh['ORDER_CREATION_DATE']>harsh['REQUESTED_DELIVERY_DATE']).sum()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ef3b0",
   "metadata": {
    "id": "5a7ef3b0"
   },
   "source": [
    "10. Remove those records where order date is greater than the delivery date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47299e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "fb47299e",
    "outputId": "13a02cf7-a0a1-451f-97f1-d5d1a55e6570"
   },
   "outputs": [],
   "source": [
    "a=harsh['ORDER_CREATION_DATE']>harsh['REQUESTED_DELIVERY_DATE']\n",
    "harsh=harsh.loc[~a]\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15be11",
   "metadata": {
    "id": "9c15be11"
   },
   "source": [
    "11. Check the number of records where the “ORDER_AMOUNT” field is having “-” in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879dfc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a879dfc3",
    "outputId": "ba9124d5-0406-49f6-d8ae-ec34ba7557da"
   },
   "outputs": [],
   "source": [
    "a=(harsh['ORDER_AMOUNT'].str.contains('-')).sum()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfdaba8",
   "metadata": {
    "id": "7cfdaba8"
   },
   "source": [
    "12. Replace “-” with “” from the “ORDER_AMOUNT” field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948ce54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "b948ce54",
    "outputId": "3531c32d-90f7-419f-97e9-fc795874a368"
   },
   "outputs": [],
   "source": [
    "harsh['ORDER_AMOUNT']=harsh['ORDER_AMOUNT'].str.replace(\"-\",'')\n",
    "harsh['RELEASED_CREDIT_VALUE']=harsh['RELEASED_CREDIT_VALUE'].str.replace(\"-\",'')\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89af61d",
   "metadata": {
    "id": "f89af61d"
   },
   "source": [
    "13. Check the number of records where the “ORDER_AMOUNT” field is having “,” in it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535102f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "535102f4",
    "outputId": "e9b60bea-58be-4a74-ef3e-a9e5c7d85ac0"
   },
   "outputs": [],
   "source": [
    "a=(harsh['ORDER_AMOUNT'].str.contains(',')).sum()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed63628",
   "metadata": {
    "id": "4ed63628"
   },
   "source": [
    "14. Replace “,” with “.” from the “ORDER_AMOUNT” field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ec4e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "8e0ec4e8",
    "outputId": "0b8dbd96-aca4-4839-bd9d-897e5f92a011"
   },
   "outputs": [],
   "source": [
    "harsh['ORDER_AMOUNT']=harsh['ORDER_AMOUNT'].str.replace(\",\",'.')\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212ec3d",
   "metadata": {
    "id": "6212ec3d"
   },
   "source": [
    "15. Count the number of records where the order date and the delivery date are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3be8dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c3be8dd",
    "outputId": "1b871394-ebb8-4f45-b5ee-eb4f387d4611"
   },
   "outputs": [],
   "source": [
    "a=(harsh['ORDER_CREATION_DATE']==harsh['REQUESTED_DELIVERY_DATE']).sum()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ae413",
   "metadata": {
    "id": "aa2ae413"
   },
   "source": [
    "16. Count the number of records for each currency type by using the field “'ORDER_CURRENCY'”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadb35f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "ffadb35f",
    "outputId": "f213a8cb-0144-4e4f-b903-67c7022d7f94",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=(harsh.groupby('ORDER_CURRENCY')).count()\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d2d89",
   "metadata": {
    "id": "4e4d2d89"
   },
   "source": [
    "17. Create a new column in the existing dataframe as “'amount_in_usd'” and convert all the non-USD currencies in USD and store them in the same column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pd0F8OvcvMfO",
   "metadata": {
    "id": "Pd0F8OvcvMfO"
   },
   "source": [
    "harsh['amount_in_usd'] = harsh.apply(lambda x: float(x['ORDER_AMOUNT']) * float(dic[x['ORDER_CURRENCY']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb177f0",
   "metadata": {
    "id": "deb177f0"
   },
   "outputs": [],
   "source": [
    "exchange_rates = {\n",
    "    'USD':1,                                                     \n",
    "    'EUR': 1.08,   \n",
    "    'AUD': 0.65,    \n",
    "    'CAD': 0.74,    \n",
    "    'GBP': 1.24,    \n",
    "    'MYR': 0.22,    \n",
    "    'PLN': 0.24,    \n",
    "    'AED': 0.27,   \n",
    "    'HKD': 0.13,     \n",
    "    'CHF': 1.11,     \n",
    "    'RON': 0.22,     \n",
    "    'SGD': 0.74,     \n",
    "    'CZK': 0.045,     \n",
    "    'HU1': 0.0029,     \n",
    "    'NZD': 0.61,       \n",
    "    'BHD': 2.65,      \n",
    "    'SAR': 0.27,       \n",
    "    'QAR': 0.27,       \n",
    "    'KWD': 3.25,       \n",
    "    'SEK': 0.094\n",
    "}\n",
    "harsh['amount_in_usd'] = harsh['ORDER_AMOUNT'].astype(float) * harsh['ORDER_CURRENCY'].map(exchange_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d81404",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "95d81404",
    "outputId": "754b836b-bdaa-45af-9332-87df111d24d0"
   },
   "outputs": [],
   "source": [
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104d1fe",
   "metadata": {
    "id": "9104d1fe"
   },
   "source": [
    "18. Check for values “0” in the “'amount_in_usd” column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5712f94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5712f94",
    "outputId": "a1389030-cda4-4172-ab1d-e02cc03a4009"
   },
   "outputs": [],
   "source": [
    "a=(harsh['amount_in_usd']==0).sum()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0c77c",
   "metadata": {
    "id": "52c0c77c"
   },
   "source": [
    "19. Create a new column in the existing dataframe “unique_cust_id” by adding 'CUSTOMER_NUMBER' and 'COMPANY_CODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f74f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "660f74f0",
    "outputId": "9d90c7fd-a4ee-4f0a-c45e-be866d456b7a"
   },
   "outputs": [],
   "source": [
    "harsh[\"unique_cust_id\"]=str(harsh['CUSTOMER_NUMBER']) + str(harsh['COMPANY_CODE'])\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HKNU7I9WRI_8",
   "metadata": {
    "id": "HKNU7I9WRI_8"
   },
   "source": [
    "# ***Milestone 2 - EDA***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1DgitK-cqlko",
   "metadata": {
    "id": "1DgitK-cqlko"
   },
   "source": [
    "1. Create a Histogram on DISTRIBUTION_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NOKJsqWNQPn6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "NOKJsqWNQPn6",
    "outputId": "8634ba77-0e9a-4e8f-ca0b-a5e244c47362"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,10))\n",
    "plt.hist(harsh['DISTRIBUTION_CHANNEL'].sample(n=1000),color='orange',bins=100)\n",
    "#title of the histogram\n",
    "plt.title('Distribution of DISTRIBUTION_CHANNEL')\n",
    "plt.xlabel('DISTRIBUTION_CHANNEL',)\n",
    "plt.ylabel('COUNT')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lXvazxo5GUXf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "lXvazxo5GUXf",
    "outputId": "d26e212e-dc2d-4935-979a-7d15dbe87387"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,10))\n",
    "sea.histplot(harsh['DISTRIBUTION_CHANNEL'].sample(n=1000),color='orange',bins=100) #taking sample of 1000 randomly\n",
    "plt.xticks([])\n",
    "plt.xlabel('DISTRIBUTION_CHANNEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n6rhQOQsGkBI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "n6rhQOQsGkBI",
    "outputId": "86c3694b-7a59-4cdb-e82a-ec85b25c708f"
   },
   "outputs": [],
   "source": [
    "#distribution channel names are messing up with each other in histogram so I am removing it in order to make clear view\n",
    "dist_channel=harsh['DISTRIBUTION_CHANNEL'].value_counts()[:25]\n",
    "dist_others=harsh['DISTRIBUTION_CHANNEL'].value_counts()[25:].sum()\n",
    "dist_channel['others'] = dist_others\n",
    "arr=[]\n",
    "for i in range(1,27):\n",
    "    arr.append(i)\n",
    "newdfDist=pd.DataFrame(dist_channel)\n",
    "newdfDist['numbercountry']=arr\n",
    "\n",
    "#plotting histogram\n",
    "newdfDist.hist(figsize=[15,7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3C-i7f7Dqx2D",
   "metadata": {
    "id": "3C-i7f7Dqx2D"
   },
   "source": [
    "2. Create a Pie Chart on ORDER_CURRENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UOXAoTk-q4I4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "UOXAoTk-q4I4",
    "outputId": "9b7e2343-c525-4a81-f916-a7a802e8959f"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,7))\n",
    "plt.pie(harsh['ORDER_CURRENCY'].value_counts(), labels=harsh['ORDER_CURRENCY'].unique(),autopct='%1.0f%%')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(loc = 'center left',fontsize=6)\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GdmBN3dkGzIH",
   "metadata": {
    "id": "GdmBN3dkGzIH"
   },
   "source": [
    "From pie chart it can be inferred that EUR currency is mosty being order currency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bNxkIg_ewN",
   "metadata": {
    "id": "03bNxkIg_ewN"
   },
   "source": [
    "3. Create a line chart PURCHASE_ORDER_TYPE and DISTRIBUTION_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CRCfmyYN_ttO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "CRCfmyYN_ttO",
    "outputId": "a4b7166a-84e8-45b4-b3fe-26fbfbf3d62d"
   },
   "outputs": [],
   "source": [
    "#'value' must be an instance of str or bytes, not a float so converting it into list \n",
    "harsh_array = harsh['PURCHASE_ORDER_TYPE'].tolist()\n",
    "plt.plot(harsh_array, harsh['DISTRIBUTION_CHANNEL'],'o-', linewidth=2)\n",
    "# Set the title and labels\n",
    "plt.title('PURCHASE_ORDER_TYPE vs DISTRIBUTION_CHANNEL')\n",
    "plt.xlabel('PURCHASE_ORDER_TYPE')\n",
    "plt.ylabel('DISTRIBUTION_CHANNEL')\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_xeZvlhjAMW6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "_xeZvlhjAMW6",
    "outputId": "e195899a-7837-482a-9cce-c1d95fafdbd5"
   },
   "outputs": [],
   "source": [
    "#Seeing above it is looking messy so , i am taking sample of it and then proceeding\n",
    "sample_df = harsh.sample(n=100, random_state=42) \n",
    "plt.subplots(figsize=(15,7))\n",
    "df_array = sample_df['PURCHASE_ORDER_TYPE'].tolist()\n",
    "plt.plot(sample_df['DISTRIBUTION_CHANNEL'],df_array,'og-', linewidth=2)\n",
    "plt.title('PURCHASE_ORDER_TYPE vs DISTRIBUTION_CHANNEL')\n",
    "plt.xlabel('DISTRIBUTION_CHANNEL')\n",
    "plt.ylabel('PURCHASE_ORDER_TYPE')\n",
    "plt.yticks([]) #removing the label values because it was messing with other values and making visual poor.\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RJeosccgAOPM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "RJeosccgAOPM",
    "outputId": "9ca3b336-26ba-425e-9e48-2715f0466684"
   },
   "outputs": [],
   "source": [
    "# Both are categorical value so we can go for separate line plots which is done below separaterly\n",
    "# for PURCHASE_ORDER_TYPE\n",
    "purchaseOrderType=harsh['PURCHASE_ORDER_TYPE'].value_counts()[:20]\n",
    "purchaseOthers=harsh['PURCHASE_ORDER_TYPE'].value_counts()[20:].sum()\n",
    "purchaseOrderType['others'] = purchaseOthers\n",
    "newDfPurchase = pd.DataFrame(purchaseOrderType)\n",
    "#standardizing the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "  \n",
    "# transform data\n",
    "newdfStand= scaler.fit_transform(newDfPurchase)\n",
    "newdfStand = pd.DataFrame(newdfStand)\n",
    "newDfPurchase['Standardized Data']=newdfStand[0].astype(float).values\n",
    "\n",
    "#plotting\n",
    "newDfPurchase.plot.line()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwKmqTNdAj9w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "iwKmqTNdAj9w",
    "outputId": "a020f6da-e47b-4d42-8d43-7e61999baf16"
   },
   "outputs": [],
   "source": [
    "#for distribution channel\n",
    "##DISTRIBUTION_CHANNEL\n",
    "dist_chnl=harsh['DISTRIBUTION_CHANNEL'].value_counts()[:21]\n",
    "others_chnl=harsh['DISTRIBUTION_CHANNEL'].value_counts()[21:].sum()\n",
    "dist_chnl['others'] = others_chnl\n",
    "#create new dataframe\n",
    "newdfChnl=pd.DataFrame(dist_chnl)\n",
    "newdfChnl.plot.line()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1LGvuL08CkYo",
   "metadata": {
    "id": "1LGvuL08CkYo"
   },
   "source": [
    "4. Create a line plot on ORDER_CREATION_DATE and amount_in_usd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KBC48dNHCtbA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "KBC48dNHCtbA",
    "outputId": "0fd7362a-4f7d-472f-ef46-6e77190e5f5e"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,7))\n",
    "# Create the line chart\n",
    "plt.plot(harsh['ORDER_CREATION_DATE'], harsh['amount_in_usd'], 'o-b', linewidth=2)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('ORDER_CREATION_DATE vs amount_in_usd')\n",
    "plt.xlabel('ORDER_CREATION_DATE')\n",
    "plt.ylabel('amount_in_usd')\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ooVGsf6YCtg2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "ooVGsf6YCtg2",
    "outputId": "eb43e81a-f13b-4e86-9355-426e1971f562"
   },
   "outputs": [],
   "source": [
    "# Prepare the sample data\n",
    "sample_df = harsh.sample(n=1000)\n",
    "plt.subplots(figsize=(15,7))\n",
    "# Convert 'ORDER_AMOUNT' to numeric type\n",
    "sample_df['amount_in_usd'] = pd.to_numeric(sample_df['ORDER_AMOUNT'], errors='coerce')\n",
    "\n",
    "# Group data by 'ORDER_CREATION_DATE' and calculate the sum of 'amount_in_usd'\n",
    "grouped_data = sample_df.groupby('ORDER_CREATION_DATE')['amount_in_usd'].sum()\n",
    "\n",
    "# Create the line plot\n",
    "grouped_data.plot(kind='line',color='brown')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Order Creation Date')\n",
    "plt.ylabel('Amount in USD')\n",
    "plt.title('Line Plot of Order Creation Date and Amount in USD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KE9jS6jcCtjZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "KE9jS6jcCtjZ",
    "outputId": "ee953c07-86d3-4cb4-ecca-593e7245273e"
   },
   "outputs": [],
   "source": [
    "#it looks bad so lets do it separately \n",
    "#for ORDER_CREATION_DATE attribute\n",
    "order=harsh['ORDER_CREATION_DATE'].value_counts()[:25]\n",
    "others_order=harsh['ORDER_CREATION_DATE'].value_counts()[25:].sum()\n",
    "order['others'] = others_order\n",
    "order.plot.line(figsize=[15,7])\n",
    "plt.xlabel('ORDER_CREATION_DATE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PFF8QJyYCtmN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "PFF8QJyYCtmN",
    "outputId": "e0709c65-3c87-4dcc-c07a-aa7a043b68a6"
   },
   "outputs": [],
   "source": [
    "#for amount_in_usd attribute\n",
    "amount=harsh['amount_in_usd'].value_counts()\n",
    "others_amount=harsh['amount_in_usd'].value_counts().sum()\n",
    "amount['others'] = others_amount\n",
    "amount.plot.line(figsize=[15,7])\n",
    "plt.xlabel('amount_in_usd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tbc7JodnD60F",
   "metadata": {
    "id": "Tbc7JodnD60F"
   },
   "source": [
    "5. Create a boxplot on ORDER_AMOUNT\tto find out the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fn3nJKAFCtoy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "Fn3nJKAFCtoy",
    "outputId": "392e9ea4-4814-45f5-9a74-22d0b6256fda"
   },
   "outputs": [],
   "source": [
    "#converting type to float so that it will do the calculation because it is in string format\n",
    "order_amounts = harsh['ORDER_AMOUNT'].astype(float)\n",
    "plt.subplots(figsize=(15,7))\n",
    "plt.boxplot(order_amounts, 0, 'gs', 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jb_VWoKmCtrh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "jb_VWoKmCtrh",
    "outputId": "330f0ac0-869e-45b2-8772-fa703651d9ef"
   },
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame(order_amounts)\n",
    "plt.figure(figsize=(15,7))\n",
    "sea.boxplot(data=newdf, showfliers=False, saturation=1,color = 'skyblue')\n",
    "plt.title(\"Boxplot for Order Amount\", fontsize = 25)\n",
    "plt.xlabel(\"Indices\", size=12)\n",
    "plt.ylabel('Order Amount', size=12)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0BGVE2ayFK9X",
   "metadata": {
    "id": "0BGVE2ayFK9X"
   },
   "source": [
    "6. Create a barchart on COMPANY_CODE and ORDER_AMOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "njvCK3sGCttu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "njvCK3sGCttu",
    "outputId": "396cf40e-9244-47f9-c1f2-8c5bcf5ca64d"
   },
   "outputs": [],
   "source": [
    "#using sample dataframe\n",
    "plt.subplots(figsize=(15,7))\n",
    "sample_df = harsh.sample(n=10000, random_state=42) \n",
    "ax = sea.barplot(x='ORDER_AMOUNT', y='COMPANY_CODE', data=sample_df)\n",
    "plt.title(\"Barchart of ordered amount and company code  \")\n",
    "plt.xticks(rotation=90) \n",
    "plt.xticks([]) #all x-axis label value were messing so i removed it to look pretty\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QNndNL9mCtxK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "QNndNL9mCtxK",
    "outputId": "7df8f113-f4fd-4927-c31f-6c90e8a9abec"
   },
   "outputs": [],
   "source": [
    "#Above chart is to messy so in order to view it clearly taking only 20 samples\n",
    "plt.subplots(figsize=(15,7))\n",
    "sample_df = harsh.sample(n=20, random_state=42) \n",
    "ax = sea.barplot(x='ORDER_AMOUNT', y='COMPANY_CODE', data=sample_df)\n",
    "plt.title(\"Barchart of ordered amount and company code  \")\n",
    "plt.xticks(rotation=90) \n",
    " #all x-axis label value were messing so i removed it to look pretty\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IK3PVtjhCtzx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "IK3PVtjhCtzx",
    "outputId": "20b935bd-b38a-46f2-d97e-cde8e7d1e2d8"
   },
   "outputs": [],
   "source": [
    "#To visualize in proper way we can use some another method by visualizing both features separately\n",
    "newDataFrame=harsh['COMPANY_CODE'].value_counts()[:32]\n",
    "others=harsh['COMPANY_CODE'].value_counts()[32:].sum()\n",
    "newDataFrame['others']=others\n",
    "newDataFrame.plot(kind='bar',figsize=[15,7],xlabel='Company Code',ylabel='Counts',rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FudDrfv2Ct3k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "FudDrfv2Ct3k",
    "outputId": "01b06c42-b2ba-4b86-80c5-74e1fb8f80f0"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,7))\n",
    "newDataFrame1=harsh['ORDER_AMOUNT'].value_counts()[:20]\n",
    "others1=harsh['ORDER_AMOUNT'].value_counts()[20:].sum()\n",
    "newDataFrame1['others'] = others1\n",
    "newDataFrame1.plot(kind='bar',figsize=[15,7],xlabel='Order Amount',ylabel='Counts',rot=0,width=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uSI-1MJuRdA0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "uSI-1MJuRdA0",
    "outputId": "428ff5eb-615d-42ae-98c7-9ce44e4a12f5"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(harsh['ORDER_AMOUNT'].astype('float64'))\n",
    "plt.ylabel('ORDER_AMOUNT')\n",
    "plt.title('Boxplot of ORDER_AMOUNT to find outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wG1hImNKkpEx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "wG1hImNKkpEx",
    "outputId": "1b88fc85-1d2f-491e-bc46-9b893f65035c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,6))\n",
    "sns.boxplot(x=harsh['amount_in_usd'])\n",
    "plt.title('Boxplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vBMmKuQaroUh",
   "metadata": {
    "id": "vBMmKuQaroUh"
   },
   "source": [
    "# Milestone 3 - Feature Engineering and Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qLwpOVPks4YC",
   "metadata": {
    "id": "qLwpOVPks4YC"
   },
   "source": [
    "1. Check for the outliers in the “amount_in_usd” column and replace the outliers with appropriate values, discussed in the sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WEGTZR_ksJnU",
   "metadata": {
    "id": "WEGTZR_ksJnU"
   },
   "outputs": [],
   "source": [
    "Q1=harsh[\"amount_in_usd\"].quantile(0.25)\n",
    "Q2=harsh[\"amount_in_usd\"].median()\n",
    "Q3=harsh[\"amount_in_usd\"].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - (1.5 * IQR)\n",
    "upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "# Identify outliers\n",
    "outliers = harsh[(harsh['amount_in_usd'] < lower_bound) | (harsh['amount_in_usd'] > upper_bound)]\n",
    "harsh.loc[(harsh['amount_in_usd'] < lower_bound) | (harsh['amount_in_usd'] > upper_bound), 'amount_in_usd'] = Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OTUm_v02TS8i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTUm_v02TS8i",
    "outputId": "a76a9eba-f90e-4df2-8242-2cc0bcef5783"
   },
   "outputs": [],
   "source": [
    "outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hvA6ZaayeNb9",
   "metadata": {
    "id": "hvA6ZaayeNb9"
   },
   "outputs": [],
   "source": [
    "## Now finding by using Standard deviation\n",
    "\n",
    "mean_value = harsh['amount_in_usd'].mean()\n",
    "std_value = harsh['amount_in_usd'].std()\n",
    "\n",
    "# Define the threshold for outliers (e.g., 3 standard deviations)\n",
    "threshold = 1\n",
    "\n",
    "# Identify outliers\n",
    "outliers1 = harsh[(harsh['amount_in_usd'] - mean_value).abs() > threshold * std_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KQyrlao_e5Gy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQyrlao_e5Gy",
    "outputId": "660be549-5413-426d-e0ef-915e87381fac"
   },
   "outputs": [],
   "source": [
    "outliers1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pu8EtSPDL96q",
   "metadata": {
    "id": "pu8EtSPDL96q"
   },
   "source": [
    "2. Label encoding or One hot Encoding on all the categorical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vAFy09ZYFP2Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "vAFy09ZYFP2Y",
    "outputId": "b7a565f6-9340-4b71-d0c3-0430ab411f50"
   },
   "outputs": [],
   "source": [
    "display(harsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZvRnBKaqFJgK",
   "metadata": {
    "id": "ZvRnBKaqFJgK"
   },
   "outputs": [],
   "source": [
    "#converting datatypes into float \n",
    "harsh[\"ORDER_AMOUNT\"]=harsh[\"ORDER_AMOUNT\"].astype(float)\n",
    "harsh['RELEASED_CREDIT_VALUE']=harsh['RELEASED_CREDIT_VALUE'].str.replace(\",\",'.')\n",
    "harsh[\"RELEASED_CREDIT_VALUE\"]=harsh[\"RELEASED_CREDIT_VALUE\"].astype(float)\n",
    "harsh[\"CREDIT_STATUS\"]=harsh[\"CREDIT_STATUS\"].astype(float)\n",
    "harsh=harsh.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RmLskBlJFKsP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmLskBlJFKsP",
    "outputId": "838c1dbf-caae-4ca8-f8e5-5478083f1b72"
   },
   "outputs": [],
   "source": [
    "harsh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZfRUn_8hNIXF",
   "metadata": {
    "id": "ZfRUn_8hNIXF"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Separate categorical and numerical columns\n",
    "cat=[]\n",
    "num=[]\n",
    "for i in harsh.columns:\n",
    "  if harsh[i].dtype==\"string\" :\n",
    "    cat.append(i)\n",
    "  elif harsh[i].dtype==\"Int64\" or harsh[i].dtype==\"Float64\":\n",
    "    num.append(i)\n",
    "\n",
    "ans=cat+num\n",
    "\n",
    "#changeing datatype of catagorical values string to catagory\n",
    "harsh[cat]=harsh[cat].astype('category')\n",
    "harsh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EZVJO9g5xIm4",
   "metadata": {
    "id": "EZVJO9g5xIm4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Label encode categorical columns\n",
    "le = LabelEncoder()\n",
    "harsh[cat] = harsh[cat].apply(le.fit_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aghKhuY1L-Sq",
   "metadata": {
    "id": "aghKhuY1L-Sq"
   },
   "source": [
    "3. Log Transformations on continuous columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Jh8EMkd1EUf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "0Jh8EMkd1EUf",
    "outputId": "3a1bdc3d-53c2-4cca-c881-9bfea03844c8"
   },
   "outputs": [],
   "source": [
    "harsh[num] = np.log(harsh[num])\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h29j1aZkL-eX",
   "metadata": {
    "id": "h29j1aZkL-eX"
   },
   "source": [
    "4. Try to extract new features by grouping existing columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have not grouped any one as I don't require it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F6sK6Hb7L-o0",
   "metadata": {
    "id": "F6sK6Hb7L-o0"
   },
   "source": [
    "5. Create a heatmap to find correlation between the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aztXTWPro-pa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "aztXTWPro-pa",
    "outputId": "96592192-a67e-4c21-b0cf-ea40570fd191"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,7))\n",
    "corr_matrix=harsh.corr()\n",
    "sea.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cu6RcnCAXRoV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "Cu6RcnCAXRoV",
    "outputId": "75cdf480-7d35-4625-c5d5-0cfa4e2c6116"
   },
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gpPos7mKL-1w",
   "metadata": {
    "id": "gpPos7mKL-1w"
   },
   "source": [
    "6. Try to identify important or relevant columns for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rBejnPf8hpJq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBejnPf8hpJq",
    "outputId": "8a4e2622-6457-4406-e45c-ca97285f49e9"
   },
   "outputs": [],
   "source": [
    "corr_matrix=harsh.corr()\n",
    "\n",
    "threshold = 0.5  # Set the correlation threshold\n",
    "relevant_columns = []\n",
    "\n",
    "for col in corr_matrix.columns:\n",
    "    if abs(corr_matrix['amount_in_usd'][col]) >= threshold:  # Check correlation with the target variable\n",
    "        relevant_columns.append(col)\n",
    "\n",
    "print('Relevant columns for feature extraction:', relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0345a",
   "metadata": {},
   "source": [
    "# Milestone 4 - ML Models and Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ff3ae",
   "metadata": {},
   "source": [
    "1. Modify the dataset to pass into any type of machine learning models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a262a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding sum new columns to dataset which are relevent for pridiction\n",
    "harsh=difference_in_days(harsh,5,1,\"unique_cust_id\",\"ORDER_CREATION_DATE\",\"amount_in_usd\")\n",
    "display(harsh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Ploting the heatmap after adding new columns \n",
    "plt.subplots(figsize=(15,7))\n",
    "corr_matrix=harsh.corr()\n",
    "sea.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21380208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to identify important or relevant columns for feature extraction\n",
    "\n",
    "threshold = 0.5  # Set the correlation threshold\n",
    "relevant = []\n",
    "\n",
    "for col in corr_matrix.columns:\n",
    "    if abs(corr_matrix['amount_in_usd'][col]) >= threshold:  # Check correlation with the target variable\n",
    "        relevant.append(col)\n",
    "\n",
    "print('Relevant columns for feature extraction:', relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80228478",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here I am dropping RELEASED_CREDIT_VALUE as it has 93% null values\n",
    "harsh=harsh.drop(\"RELEASED_CREDIT_VALUE\",axis =1)\n",
    "#Removing this column as this has no use as we are using column \"amount_in_usd\"\n",
    "harsh=harsh.drop(\"ORDER_AMOUNT\",axis=1)\n",
    "#now dropping column containg Date \n",
    "harsh=harsh.drop([\"ORDER_CREATION_DATE\",\"REQUESTED_DELIVERY_DATE\"],axis =1)\n",
    "#now droping unique_cust_id column as it is not usabele for pridiction\n",
    "harsh=harsh.drop(\"unique_cust_id\",axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5be0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "harsh = harsh.fillna(harsh.mean())\n",
    "\n",
    "harsh = harsh.apply(lambda col: col.fillna(col.mean()), axis=1)\n",
    "\n",
    "display(harsh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae08b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing infineite value with 0\n",
    "harsh.replace([np.nan, -np.inf], 0, inplace=True)\n",
    "\n",
    "#harsh = harsh.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "display(harsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,7))\n",
    "corr_matrix=harsh.corr()\n",
    "sea.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8982a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(harsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb10d26",
   "metadata": {},
   "source": [
    "2. Try different machine learning models like - \n",
    "a Linear Regression\n",
    "b Support Vector Machine \n",
    "c Decision Tree\n",
    "d Random Forest \n",
    "e AdaBoost\n",
    "f Xgboost etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b58add",
   "metadata": {},
   "source": [
    "3. Perform Regression model evaluations like MSE, RMSE, R-Square etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85b232",
   "metadata": {},
   "source": [
    "I have done both the questions together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comman function for every learning model to training and finding it's accuracy\n",
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred1 = model.predict(X_train)\n",
    "    print('Model Performance for {}'.format(model.__class__.__name__))\n",
    "    print('R2: ', r2_score(y_test, y_pred))\n",
    "    print('R2 for traning: ', r2_score(y_train, y_pred1))\n",
    "    print('MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b991c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "harsh1=harsh[['CREDIT_STATUS',\n",
    " 'amount_in_usd',\n",
    " 'Last-1day_Sales',\n",
    " 'Last-2day_Sales',\n",
    " 'Last-3day_Sales',\n",
    " 'Last-4day_Sales',\n",
    " 'Last-5day_Sales',\n",
    " 'Last-1day_Diff',\n",
    " 'Last-2day_Diff',\n",
    " 'Last-3day_Diff',\n",
    " 'Last-4day_Diff',\n",
    " 'Last-5day_Diff']]\n",
    "\n",
    "harsh1.replace([np.nan, -np.inf], 0, inplace=True)\n",
    "\n",
    "harsh1 = harsh1.apply(lambda col: col.fillna(col.mean()), axis=1)\n",
    "\n",
    "display(harsh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ffaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan_or_inf = harsh1.isnull().any(axis=1) | harsh1.isin([np.inf, -np.inf]).any(axis=1)\n",
    "\n",
    "# Count rows with NaN or inf values\n",
    "numrows = has_nan_or_inf.sum()\n",
    "\n",
    "print(numrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating training and testing data\n",
    "x=harsh1.drop('amount_in_usd',axis =1)\n",
    "y=harsh1[\"amount_in_usd\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Your code here\n",
    "\n",
    "evaluate(LinearRegression(), X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(DecisionTreeRegressor(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d25095",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ExtraTreesRegressor(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705df972",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(AdaBoostRegressor(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af518d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "harsh1=harsh[[ 'CREDIT_STATUS','amount_in_usd','Last-1day_Sales','Last-2day_Sales','Last-3day_Sales','Last-4day_Sales','Last-5day_Sales']]\n",
    "x=harsh1.drop('amount_in_usd',axis =1)\n",
    "y=harsh1[\"amount_in_usd\"]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=4)\n",
    "\n",
    "# Create a DMatrix for XGBoost (an internal data structure used by XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train,enable_categorical='true')\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Set hyperparameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # For regression tasks\n",
    "    'max_depth': 100,  # Maximum depth of each tree\n",
    "    'eta': 0.1,  # Learning rate\n",
    "    'subsample': 0.7,  # Fraction of training data used in each boosting round\n",
    "    'colsample_bytree': 0.9,  # Fraction of features used in each boosting round\n",
    "    'num_boost_round': 10  # Number of boosting rounds (trees)\n",
    "}    \n",
    "\n",
    "# Train the XGBoost regressor\n",
    "model = xgb.train(params, dtrain)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r21 = r2_score(y_pred, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared (R2) Score: {r2}\")\n",
    "print(f\"R-squared (R2) for test Score: {r21}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plot_importance(model)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(RandomForestRegressor(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22420633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset or create X (input features) and y (target variable)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = RandomForestRegressor(max_depth=12, max_features='sqrt', max_leaf_nodes=16,n_estimators=150)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cross_val_scores = cross_val_score(model, x, y, cv=k, scoring='r2')\n",
    "\n",
    "# Print the R2 scores obtained from each fold\n",
    "for fold, score in enumerate(cross_val_scores):\n",
    "    print(f\"Fold {fold+1}: R2 Score = {score}\")\n",
    "\n",
    "# Calculate the average R2 score and its standard deviation\n",
    "avg_score = np.mean(cross_val_scores)\n",
    "std_dev = np.std(cross_val_scores)\n",
    "\n",
    "print(f\"\\nAverage R2 Score: {avg_score}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(svm.SVR(), X_train, y_train, X_test, y_test)\n",
    "#I have executed it but I am not including it as it is too long to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e0266",
   "metadata": {},
   "source": [
    "4. Compare the accuracies of all the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2656804e",
   "metadata": {},
   "source": [
    "5. Select the best possible model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622a02f",
   "metadata": {},
   "source": [
    "6. Perform Hyperparameter tuning, select best hyperparameters by using appropriate algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am using RandomsearchCV for hyperperameter tuning of my model\n",
    "# Necessary imports\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Creating the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150,200],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10,12,16],\n",
    "    'max_leaf_nodes': [12,14,16],\n",
    "    'criterion': ['squared_error'],\n",
    "    'min_samples_split': [4,5,6],\n",
    "    'min_samples_leaf': [3,4,5] ,\n",
    "    'min_weight_fraction_leaf': [0] ,\n",
    "    'min_impurity_decrease': [1,2,3],\n",
    "    'bootstrap': ['true'],\n",
    "    'oob_score': ['true'],\n",
    "    'n_jobs': [2,3,4],\n",
    "    'random_state': [20,30,40],\n",
    "    'verbose': [0],\n",
    "    'warm_start': ['true'],\n",
    "    'ccp_alpha': [2,1,4],\n",
    "    'max_samples': [20,30,40]\n",
    "}\n",
    "\n",
    "# Instantiating RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(RandomForestRegressor(),param_grid)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ccca7",
   "metadata": {},
   "source": [
    "7. Come up with the best possible model accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98608743",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ExtraTreesRegressor(bootstrap=True, ccp_alpha=2, max_depth=16,\n",
    "                    max_features=None, max_leaf_nodes=12, max_samples=30,\n",
    "                    min_impurity_decrease=2, min_samples_leaf=5,\n",
    "                    min_samples_split=4, min_weight_fraction_leaf=0, n_jobs=4,\n",
    "                    oob_score=True, random_state=20, warm_start=True),X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a281500",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(RandomForestRegressor(bootstrap=True, ccp_alpha=2, max_depth=16,\n",
    "                      max_features='sqrt', max_leaf_nodes=14, max_samples=30,\n",
    "                      min_impurity_decrease=2, min_samples_leaf=3,\n",
    "                      min_samples_split=6, min_weight_fraction_leaf=0, n_jobs=4,\n",
    "                      oob_score=True, random_state=30, warm_start=True),X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad04fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(RandomForestRegressor(),param_grid,cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(random_search.best_estimator_)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we are getting less accuracy than original regressor we will not use this updated model for training propose\n",
    "\n",
    "#We will use Random forest for Pridiction as it is having highest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of decision trees in the random forest\n",
    "    'max_depth': [ 10,12,16],  # Maximum depth of each decision tree\n",
    "    'min_samples_split': [5, 10,15],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [2, 4 , 8],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'log2']  # Maximum number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "\n",
    "tree = RandomForestRegressor()\n",
    "\n",
    "# Instantiating RandomizedSearchCV object\n",
    "grid_search = GridSearchCV(RandomForestRegressor(),param_grid,cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(random_search.best_estimator_)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Load your dataset or create X (input features) and y (target variable)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Create the model\n",
    "model = MLPRegressor(validation_fraction=0.2, n_iter_no_change=10)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model's performance on test data or using cross-validation\n",
    "test_score = model.score(X_test, y_test)\n",
    "test_score2 = model.score(X_train, y_train)\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(f\"Train Score: {test_score2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e25416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load your dataset or create X (input features) and y (target variable)\n",
    "\n",
    "# Create the model with regularization\n",
    "model = Ridge(alpha=0.5)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(model, x, y, cv=k, scoring='r2')\n",
    "\n",
    "# Print the average R2 score\n",
    "avg_score = cross_val_scores.mean()\n",
    "print(f\"Average R2 Score: {avg_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f3568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the DataFrame using the encoder\n",
    "harsh1 = pd.DataFrame(encoder.fit_transform(harsh[cat]).toarray())\n",
    "\n",
    "# Get the column names for the one-hot encoded column\n",
    "\n",
    "# Rename the DataFrame columns\n",
    "df_encoded.columns = encoded_columns\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded DataFrame\n",
    "harsh1 = pd.concat([harsh, harsh1], axis=1)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(harsh1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "harsh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(bootstrap=True, ccp_alpha=2, max_depth=16,\n",
    "                      max_features='sqrt', max_leaf_nodes=14, max_samples=30,\n",
    "                      min_impurity_decrease=2, min_samples_leaf=3,\n",
    "                      min_samples_split=6, min_weight_fraction_leaf=0, n_jobs=4,\n",
    "                      oob_score=True, random_state=30, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9244f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred1 = model.predict(X_train)\n",
    "print('Model Performance for {}'.format(model.__class__.__name__))\n",
    "print('R2: ', r2_score(y_test, y_pred))\n",
    "print('R2 for traning: ', r2_score(y_train, y_pred1))\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5848a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('final1_model.sav', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8fc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a898c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b11a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60848d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1556484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c9c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e5cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62a3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "harsh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
